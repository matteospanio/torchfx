
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Performance Optimization and Benchmarking &#8212; TorchFX 1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=6f8f3740"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs";

const defaultStyle = document.createElement('style');
defaultStyle.textContent = `pre.mermaid {
    /* Same as .mermaid-container > pre */
    display: block;
    width: 100%;
}

pre.mermaid > svg {
    /* Same as .mermaid-container > pre > svg */
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}
`;
document.head.appendChild(defaultStyle);

const fullscreenStyle = document.createElement('style');
fullscreenStyle.textContent = `.mermaid-container {
    display: flex;
    flex-direction: row;
    width: 100%;
}

.mermaid-container > pre {
    display: block;
    width: 100%;
}

.mermaid-container > pre > svg {
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}

.mermaid-fullscreen-btn {
    width: 28px;
    height: 28px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.3);
    border-radius: 4px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
    font-size: 14px;
    line-height: 1;
    padding: 0;
    color: #333;
}

.mermaid-fullscreen-btn:hover {
    opacity: 100% !important;
    background: rgba(255, 255, 255, 1);
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
    transform: scale(1.1);
}

.mermaid-fullscreen-btn.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.3);
    color: #e0e0e0;
}

.mermaid-fullscreen-btn.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 3px 10px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal {
    display: none;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    width: 95vw;
    height: 100vh;
    background: rgba(255, 255, 255, 0.98);
    z-index: 9999;
    padding: 20px;
    overflow: auto;
}

.mermaid-fullscreen-modal.dark-theme {
    background: rgba(0, 0, 0, 0.98);
}

.mermaid-fullscreen-modal.active {
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen {
    position: relative;
    width: 95vw;
    height: 90vh;
    max-width: 95vw;
    max-height: 90vh;
    background: white;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
    overflow: auto;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen.dark-theme {
    background: #1a1a1a;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.8);
}

.mermaid-container-fullscreen pre.mermaid {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen .mermaid svg {
    height: 100% !important;
    width: 100% !important;
    cursor: grab;
}

.mermaid-fullscreen-close {
    position: fixed !important;
    top: 20px !important;
    right: 20px !important;
    width: 40px;
    height: 40px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 50%;
    cursor: pointer;
    z-index: 10000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: all 0.2s;
    font-size: 24px;
    line-height: 1;
    color: #333;
}

.mermaid-fullscreen-close:hover {
    background: white;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    transform: scale(1.1);
}

.mermaid-fullscreen-close.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.2);
    color: #e0e0e0;
}

.mermaid-fullscreen-close.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 6px 16px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal .mermaid-fullscreen-btn {
    display: none !important;
}`;
document.head.appendChild(fullscreenStyle);

// Detect if page has dark background
const isDarkTheme = () => {
    const bgColor = window.getComputedStyle(document.body).backgroundColor;
    const match = bgColor.match(/rgb\((\d+),\s*(\d+),\s*(\d+)/);
    if (match) {
        const r = parseInt(match[1]);
        const g = parseInt(match[2]);
        const b = parseInt(match[3]);
        const brightness = (r * 299 + g * 587 + b * 114) / 1000;
        return brightness < 128;
    }
    return false;
};

const load = async () => {
    await mermaid.run();

    const all_mermaids = document.querySelectorAll(".mermaid");
    const mermaids_processed = document.querySelectorAll(".mermaid[data-processed='true']");

    if ("False" === "True") {
        const mermaids_to_add_zoom = -1 === -1 ? all_mermaids.length : -1;
        if(mermaids_to_add_zoom > 0) {
            var svgs = d3.selectAll("");
            if(all_mermaids.length !== mermaids_processed.length) {
                setTimeout(load, 200);
                return;
            } else if(svgs.size() !== mermaids_to_add_zoom) {
                setTimeout(load, 200);
                return;
            } else {
                svgs.each(function() {
                    var svg = d3.select(this);
                    svg.html("<g class='wrapper'>" + svg.html() + "</g>");
                    var inner = svg.select("g");
                    var zoom = d3.zoom().on("zoom", function(event) {
                        inner.attr("transform", event.transform);
                    });
                    svg.call(zoom);
                });
            }
        }
    } else if(all_mermaids.length !== mermaids_processed.length) {
        // Wait for mermaid to process all diagrams
        setTimeout(load, 200);
        return;
    }

    const darkTheme = isDarkTheme();

    // Stop here if not adding fullscreen capability
    if ("True" !== "True") return;

    const modal = document.createElement('div');
    modal.className = 'mermaid-fullscreen-modal' + (darkTheme ? ' dark-theme' : '');
    modal.setAttribute('role', 'dialog');
    modal.setAttribute('aria-modal', 'true');
    modal.setAttribute('aria-label', 'Fullscreen diagram viewer');
    modal.innerHTML = `
        <button class="mermaid-fullscreen-close${darkTheme ? ' dark-theme' : ''}" aria-label="Close fullscreen">✕</button>
        <div class="mermaid-container-fullscreen${darkTheme ? ' dark-theme' : ''}"></div>
    `;
    document.body.appendChild(modal);

    const modalContent = modal.querySelector('.mermaid-container-fullscreen');
    const closeBtn = modal.querySelector('.mermaid-fullscreen-close');

    let previousScrollOffset = [window.scrollX, window.scrollY];

    const closeModal = () => {
        modal.classList.remove('active');
        modalContent.innerHTML = '';
        document.body.style.overflow = ''
        window.scrollTo({left: previousScrollOffset[0], top: previousScrollOffset[1], behavior: 'instant'});
    };

    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => {
        if (e.target === modal) closeModal();
    });
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeModal();
        }
    });

    const allButtons = [];

    document.querySelectorAll('.mermaid').forEach((mermaidDiv) => {
        if (mermaidDiv.parentNode.classList.contains('mermaid-container') ||
            mermaidDiv.closest('.mermaid-fullscreen-modal')) {
            return;
        }

        const container = document.createElement('div');
        container.className = 'mermaid-container';
        mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
        container.appendChild(mermaidDiv);

        const fullscreenBtn = document.createElement('button');
        fullscreenBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
        fullscreenBtn.setAttribute('aria-label', 'View diagram in fullscreen');
        fullscreenBtn.textContent = '⛶';
        fullscreenBtn.style.opacity = '50%';

        // Calculate dynamic position based on diagram's margin and padding
        const diagramStyle = window.getComputedStyle(mermaidDiv);
        const marginTop = parseFloat(diagramStyle.marginTop) || 0;
        const marginRight = parseFloat(diagramStyle.marginRight) || 0;
        const paddingTop = parseFloat(diagramStyle.paddingTop) || 0;
        const paddingRight = parseFloat(diagramStyle.paddingRight) || 0;
        fullscreenBtn.style.top = `${marginTop + paddingTop + 4}px`;
        fullscreenBtn.style.right = `${marginRight + paddingRight + 4}px`;

        fullscreenBtn.addEventListener('click', () => {
            previousScrollOffset = [window.scroll, window.scrollY];
            const clone = mermaidDiv.cloneNode(true);
            modalContent.innerHTML = '';
            modalContent.appendChild(clone);

            const svg = clone.querySelector('svg');
            if (svg) {
                svg.removeAttribute('width');
                svg.removeAttribute('height');
                svg.style.width = '100%';
                svg.style.height = 'auto';
                svg.style.maxWidth = '100%';
                svg.style.sdisplay = 'block';

                if ("False" === "True") {
                    setTimeout(() => {
                        const g = svg.querySelector('g');
                        if (g) {
                            var svgD3 = d3.select(svg);
                            svgD3.html("<g class='wrapper'>" + svgD3.html() + "</g>");
                            var inner = svgD3.select("g");
                            var zoom = d3.zoom().on("zoom", function(event) {
                                inner.attr("transform", event.transform);
                            });
                            svgD3.call(zoom);
                        }
                    }, 100);
                }
            }

            modal.classList.add('active');
            document.body.style.overflow = 'hidden';
        });

        container.appendChild(fullscreenBtn);
        allButtons.push(fullscreenBtn);
    });

    // Update theme classes when theme changes
    const updateTheme = () => {
        const dark = isDarkTheme();
        allButtons.forEach(btn => {
            if (dark) {
                btn.classList.add('dark-theme');
            } else {
                btn.classList.remove('dark-theme');
            }
        });
        if (dark) {
            modal.classList.add('dark-theme');
            modalContent.classList.add('dark-theme');
            closeBtn.classList.add('dark-theme');
        } else {
            modal.classList.remove('dark-theme');
            modalContent.classList.remove('dark-theme');
            closeBtn.classList.remove('dark-theme');
        }
    };

    // Watch for theme changes
    const observer = new MutationObserver(updateTheme);
    observer.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
    observer.observe(document.body, {
        attributes: true,
        attributeFilter: ['class', 'style']
    });
};

window.addEventListener("load", load);
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'guides/advanced/performance';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="API Stability and Backward Compatibility" href="../api_stability.html" />
    <link rel="prev" title="Multi-Channel Processing" href="multi-channel.html" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" /> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../blog/index/atom.xml"
  title="TorchFX Blog"
/>
  
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/tfx_black.svg" class="logo__image only-light" alt=""/>
    <img src="../../_static/tfx.svg" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">TorchFX</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../blog/index.html">
    Blog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/matteospanio/torchfx" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchfx/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../blog/index.html">
    Blog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/matteospanio/torchfx" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchfx/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../getting-started/index.html">Getting Started</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/getting_started.html">Getting Started</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core-concepts/index.html">Core Concepts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/wave.html">Wave - Digital Audio Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/fx.html">FX - Audio Effect Base Class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/pipeline-operator.html">Pipeline Operator - Functional Composition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/type-system.html">Type System - Musical Time and Audio Units</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/custom-filters.html">Creating Custom Filters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/series-parallel-filters.html">Series and Parallel Filter Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/custom-effects.html">Creating Custom Effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/multi-channel-effects.html">Multi-Channel Audio Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/bpm-delay.html">BPM-Synced Delay Effects</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Advanced Topics</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gpu-acceleration.html">GPU Acceleration</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch-integration.html">PyTorch Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="multi-channel.html">Multi-Channel Processing</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Performance Optimization and Benchmarking</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../api_stability.html">API Stability and Backward Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide.html">Migration Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developer/index.html">Developer Documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer/project-structure.html">Project Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/testing.html">Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/documentation.html">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/style_guide.html">Style Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/roadmap.html">Roadmap to v1.0.0</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Guides</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Advanced Topics</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Performance Optimization and Benchmarking</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section id="performance-optimization-and-benchmarking">
<span id="performance"></span><h1>Performance Optimization and Benchmarking<a class="headerlink" href="#performance-optimization-and-benchmarking" title="Link to this heading">#</a></h1>
<p>Learn how to measure, optimize, and maximize the performance of your TorchFX audio processing pipelines. This comprehensive guide covers benchmarking methodologies, GPU vs CPU performance comparisons, filter type trade-offs, and best practices for building high-throughput audio processing systems.</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<p>Before starting this guide, you should be familiar with:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../core-concepts/wave.html"><span class="doc">Wave - Digital Audio Representation</span></a> - Wave class fundamentals</p></li>
<li><p><a class="reference internal" href="../core-concepts/pipeline-operator.html"><span class="doc">Pipeline Operator - Functional Composition</span></a> - Pipeline operator basics</p></li>
<li><p><a class="reference internal" href="gpu-acceleration.html"><span class="doc">GPU Acceleration</span></a> - GPU device management</p></li>
<li><p><span class="xref std std-doc">../filters/iir-filters</span> - IIR filter characteristics</p></li>
<li><p><span class="xref std std-doc">../filters/fir-filters</span> - FIR filter characteristics</p></li>
</ul>
</section>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>Performance optimization in TorchFX involves understanding three key trade-offs:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Dimension</p></th>
<th class="head"><p>Trade-off</p></th>
<th class="head"><p>Optimization Strategy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Execution Backend</strong></p></td>
<td><p>GPU vs CPU vs SciPy</p></td>
<td><p>Choose based on duration, channels, batch size</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Filter Type</strong></p></td>
<td><p>FIR vs IIR</p></td>
<td><p>Balance computational cost vs phase response</p></td>
</tr>
<tr class="row-even"><td><p><strong>API Pattern</strong></p></td>
<td><p>Classes vs Sequential vs Pipe</p></td>
<td><p>Select based on ergonomics vs performance needs</p></td>
</tr>
</tbody>
</table>
</div>
<pre  class="mermaid">
        graph TB
    subgraph &quot;Performance Optimization Dimensions&quot;
        AudioTask[&quot;Audio Processing Task&quot;]

        subgraph Backend[&quot;Backend Selection&quot;]
            GPU[&quot;GPU (CUDA)&lt;br/&gt;High parallelism&quot;]
            CPU[&quot;CPU (PyTorch)&lt;br/&gt;Moderate performance&quot;]
            SciPy[&quot;SciPy&lt;br/&gt;Baseline reference&quot;]
        end

        subgraph FilterType[&quot;Filter Type&quot;]
            FIR[&quot;FIR Filters&lt;br/&gt;Linear phase&lt;br/&gt;Higher compute&quot;]
            IIR[&quot;IIR Filters&lt;br/&gt;Non-linear phase&lt;br/&gt;Lower compute&quot;]
        end

        subgraph API[&quot;API Pattern&quot;]
            Pipe[&quot;Pipeline Operator&lt;br/&gt;Auto sample rate&quot;]
            Sequential[&quot;nn.Sequential&lt;br/&gt;Standard PyTorch&quot;]
            Custom[&quot;Custom Module&lt;br/&gt;Maximum control&quot;]
        end

        AudioTask --&gt; Backend
        AudioTask --&gt; FilterType
        AudioTask --&gt; API

        Backend --&gt; Optimize[&quot;Optimized Pipeline&quot;]
        FilterType --&gt; Optimize
        API --&gt; Optimize
    end

    style AudioTask fill:#e1f5ff
    style Optimize fill:#e1ffe1
    style GPU fill:#fff5e1
    style FIR fill:#f5e1ff
    style Pipe fill:#ffe1e1
    </pre><p><strong>Performance Optimization Framework</strong> - Three key dimensions for optimizing TorchFX pipelines.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For detailed GPU acceleration patterns, see <a class="reference internal" href="gpu-acceleration.html"><span class="doc">GPU Acceleration</span></a>. For comprehensive benchmarking infrastructure, see the benchmark suite in the <code class="docutils literal notranslate"><span class="pre">benchmark/</span></code> directory.</p>
</div>
</section>
<section id="benchmark-methodology">
<h2>Benchmark Methodology<a class="headerlink" href="#benchmark-methodology" title="Link to this heading">#</a></h2>
<p>TorchFX includes a comprehensive benchmarking suite that evaluates performance across different dimensions. The suite consists of three benchmark scripts, each targeting a specific aspect of performance.</p>
<section id="benchmark-suite-architecture">
<h3>Benchmark Suite Architecture<a class="headerlink" href="#benchmark-suite-architecture" title="Link to this heading">#</a></h3>
<pre  class="mermaid">
        graph TB
    subgraph &quot;TorchFX Benchmark Suite&quot;
        API[&quot;api_bench.py&lt;br/&gt;API Pattern Comparison&quot;]
        FIR[&quot;fir_bench.py&lt;br/&gt;FIR Filter Performance&quot;]
        IIR[&quot;iir_bench.py&lt;br/&gt;IIR Filter Performance&quot;]
    end

    subgraph &quot;Common Test Parameters&quot;
        SR[&quot;Sample Rate: 44.1 kHz&quot;]
        REP[&quot;Repetitions: 50&quot;]
        Signal[&quot;Signal: Random noise&lt;br/&gt;Float32, normalized&quot;]
    end

    subgraph &quot;Variable Parameters&quot;
        Duration[&quot;Duration: 1s - 10 min&quot;]
        Channels[&quot;Channels: 1, 2, 4, 8, 12&quot;]
        Backends[&quot;Backends: GPU, CPU, SciPy&quot;]
    end

    subgraph &quot;Output&quot;
        CSV[&quot;CSV Results&lt;br/&gt;.out files&quot;]
    end

    API --&gt; SR
    FIR --&gt; SR
    IIR --&gt; SR

    API --&gt; REP
    FIR --&gt; REP
    IIR --&gt; REP

    FIR --&gt; Duration
    FIR --&gt; Channels
    IIR --&gt; Duration
    IIR --&gt; Channels

    API --&gt; Backends
    FIR --&gt; Backends
    IIR --&gt; Backends

    API --&gt; CSV
    FIR --&gt; CSV
    IIR --&gt; CSV

    style API fill:#e1f5ff
    style FIR fill:#e8f5e1
    style IIR fill:#fff5e1
    </pre><p><strong>Benchmark Suite Organization</strong> - Three complementary benchmarks measuring different performance aspects.</p>
</section>
<section id="test-signal-generation">
<h3>Test Signal Generation<a class="headerlink" href="#test-signal-generation" title="Link to this heading">#</a></h3>
<p>All benchmarks use consistent signal generation to ensure comparable results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_audio</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate multi-channel random noise for benchmarking.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample_rate : int</span>
<span class="sd">        Sample rate in Hz (typically 44100)</span>
<span class="sd">    duration : float</span>
<span class="sd">        Duration in seconds</span>
<span class="sd">    num_channels : int</span>
<span class="sd">        Number of audio channels</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    signal : np.ndarray</span>
<span class="sd">        Shape (num_channels, num_samples), float32, normalized to [-1, 1]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="n">duration</span><span class="p">))</span>
    <span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># Normalize each channel independently</span>
    <span class="n">signal</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">signal</span>
</pre></div>
</div>
<p><strong>Key Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>Distribution</strong>: Gaussian random noise (<code class="docutils literal notranslate"><span class="pre">np.random.randn</span></code>)</p></li>
<li><p><strong>Data Type</strong>: Float32 for GPU compatibility</p></li>
<li><p><strong>Normalization</strong>: Per-channel normalization to [-1, 1] range</p></li>
<li><p><strong>Deterministic</strong>: Same random seed produces consistent results (when seeded)</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Using random noise ensures benchmarks test worst-case performance without special structure or patterns that could be optimized by the hardware.</p>
</div>
</section>
<section id="timing-methodology">
<h3>Timing Methodology<a class="headerlink" href="#timing-methodology" title="Link to this heading">#</a></h3>
<p>All benchmarks use Python’s <a class="reference external" href="https://docs.python.org/3/library/timeit.html#timeit.timeit" title="(in Python v3.14)"><code class="xref py py-func docutils literal notranslate"><span class="pre">timeit.timeit()</span></code></a> for accurate timing measurements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>

<span class="c1"># Standard pattern across all benchmarks</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># Number of repetitions</span>

<span class="c1"># Time the operation</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span>
    <span class="k">lambda</span><span class="p">:</span> <span class="n">process_audio</span><span class="p">(</span><span class="n">wave</span><span class="p">,</span> <span class="n">filter_chain</span><span class="p">),</span>
    <span class="n">number</span><span class="o">=</span><span class="n">REP</span>
<span class="p">)</span>

<span class="c1"># Report average time per iteration</span>
<span class="n">avg_time</span> <span class="o">=</span> <span class="n">elapsed</span> <span class="o">/</span> <span class="n">REP</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average time: </span><span class="si">{</span><span class="n">avg_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Timing Best Practices</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Multiple Repetitions</strong>: 50 repetitions minimize variance and warm-up effects</p></li>
<li><p><strong>Lambda Wrapper</strong>: Captures all setup costs in the closure</p></li>
<li><p><strong>Average Reporting</strong>: Reports per-iteration time for easy comparison</p></li>
<li><p><strong>Excluded Overhead</strong>: Setup (loading, coefficient computation) excluded from timing</p></li>
</ol>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Timing only measures the core processing operation. Setup costs like loading audio files, computing filter coefficients, and device transfers are performed <strong>before</strong> timing begins.</p>
</div>
</section>
</section>
<section id="api-performance-comparison">
<h2>API Performance Comparison<a class="headerlink" href="#api-performance-comparison" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">api_bench.py</span></code> benchmark compares different API patterns for applying the same filter chain to audio. This helps users understand the performance and ergonomic trade-offs of different coding styles.</p>
<section id="test-configuration">
<h3>Test Configuration<a class="headerlink" href="#test-configuration" title="Link to this heading">#</a></h3>
<p><strong>Filter Chain</strong>: 6 cascaded IIR filters</p>
<ul class="simple">
<li><p>3 × High-pass Chebyshev Type I filters (20 Hz, 60 Hz, 65 Hz)</p></li>
<li><p>3 × Low-pass Butterworth filters (5000 Hz, 4900 Hz, 4850 Hz)</p></li>
</ul>
<p><strong>Test Signal</strong>: 8-channel audio, 2 minutes duration, 44.1 kHz sample rate</p>
<pre  class="mermaid">
        graph LR
    Input[&quot;Input Audio&lt;br/&gt;8 channels, 2 min&quot;] --&gt; F1[&quot;HiChebyshev1&lt;br/&gt;20 Hz&quot;]
    F1 --&gt; F2[&quot;HiChebyshev1&lt;br/&gt;60 Hz&quot;]
    F2 --&gt; F3[&quot;HiChebyshev1&lt;br/&gt;65 Hz&quot;]
    F3 --&gt; F4[&quot;LoButterworth&lt;br/&gt;5000 Hz&quot;]
    F4 --&gt; F5[&quot;LoButterworth&lt;br/&gt;4900 Hz&quot;]
    F5 --&gt; F6[&quot;LoButterworth&lt;br/&gt;4850 Hz&quot;]
    F6 --&gt; Output[&quot;Filtered Output&lt;br/&gt;8 channels, 2 min&quot;]

    style Input fill:#e1f5ff
    style Output fill:#e1ffe1
    </pre><p><strong>API Benchmark Filter Chain</strong> - Six cascaded IIR filters applied to 8-channel audio.</p>
</section>
<section id="api-pattern-1-custom-nn-module-class">
<h3>API Pattern 1: Custom nn.Module Class<a class="headerlink" href="#api-pattern-1-custom-nn-module-class" title="Link to this heading">#</a></h3>
<p>A traditional PyTorch approach using a custom <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiChebyshev1</span><span class="p">,</span> <span class="n">LoButterworth</span>

<span class="k">class</span><span class="w"> </span><span class="nc">FilterChain</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom module for filter chain.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f1</span> <span class="o">=</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f2</span> <span class="o">=</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f3</span> <span class="o">=</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f4</span> <span class="o">=</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f5</span> <span class="o">=</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4900</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f6</span> <span class="o">=</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4850</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f6</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Usage</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">FilterChain</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">fchain</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">ys</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>Sample Rate</strong>: Must be passed explicitly to <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>Reusability</strong>: Can be instantiated once and reused</p></li>
<li><p><strong>Flexibility</strong>: Full control over forward pass logic</p></li>
<li><p><strong>Overhead</strong>: Standard PyTorch <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> call overhead</p></li>
</ul>
</section>
<section id="api-pattern-2-nn-sequential">
<h3>API Pattern 2: nn.Sequential<a class="headerlink" href="#api-pattern-2-nn-sequential" title="Link to this heading">#</a></h3>
<p>Using PyTorch’s built-in <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code></a> container:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiChebyshev1</span><span class="p">,</span> <span class="n">LoButterworth</span>

<span class="c1"># Create filter chain inline</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4900</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4850</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">signal</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Apply to audio tensor</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">fchain</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">ys</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>Sample Rate</strong>: Must be passed explicitly to each filter</p></li>
<li><p><strong>Simplicity</strong>: No custom class needed</p></li>
<li><p><strong>Performance</strong>: Identical to custom <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> (same underlying mechanism)</p></li>
<li><p><strong>Flexibility</strong>: Can add/remove filters easily</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> and custom <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> classes have <strong>identical performance</strong> characteristics. The choice between them is purely about code organization and readability.</p>
</div>
</section>
<section id="api-pattern-3-pipeline-operator-pipe">
<h3>API Pattern 3: Pipeline Operator (Pipe)<a class="headerlink" href="#api-pattern-3-pipeline-operator-pipe" title="Link to this heading">#</a></h3>
<p>TorchFX’s idiomatic <a class="reference internal" href="../../glossary.html#term-Pipeline-Operator"><span class="xref std std-term">pipeline operator</span></a> pattern:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiChebyshev1</span><span class="p">,</span> <span class="n">LoButterworth</span>

<span class="c1"># Apply filters using pipe operator</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">signal</span>
    <span class="o">|</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">65</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4900</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">4850</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>Sample Rate</strong>: <strong>Automatically configured</strong> from <a class="reference internal" href="../../api/core.html#torchfx.Wave" title="torchfx.Wave"><code class="xref py py-class docutils literal notranslate"><span class="pre">Wave</span></code></a> object</p></li>
<li><p><strong>Ergonomics</strong>: Most readable and concise</p></li>
<li><p><strong>Safety</strong>: Eliminates sample rate mismatch errors</p></li>
<li><p><strong>Performance</strong>: Minimal overhead for automatic configuration</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The pipeline operator is the <strong>recommended pattern</strong> for TorchFX. It provides the best balance of readability, safety (automatic sample rate configuration), and performance.</p>
</div>
</section>
<section id="api-pattern-4-scipy-baseline">
<h3>API Pattern 4: SciPy Baseline<a class="headerlink" href="#api-pattern-4-scipy-baseline" title="Link to this heading">#</a></h3>
<p>Pure NumPy/SciPy implementation for baseline comparison:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.signal</span><span class="w"> </span><span class="kn">import</span> <span class="n">butter</span><span class="p">,</span> <span class="n">cheby1</span><span class="p">,</span> <span class="n">lfilter</span>

<span class="c1"># Pre-compute filter coefficients</span>
<span class="n">b1</span><span class="p">,</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">cheby1</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b2</span><span class="p">,</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">cheby1</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">cheby1</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b4</span><span class="p">,</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b5</span><span class="p">,</span> <span class="n">a5</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4900</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b6</span><span class="p">,</span> <span class="n">a6</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4850</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>

<span class="c1"># Apply filters sequentially</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">a3</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b4</span><span class="p">,</span> <span class="n">a4</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b5</span><span class="p">,</span> <span class="n">a5</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b6</span><span class="p">,</span> <span class="n">a6</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>Performance</strong>: Optimized C implementation</p></li>
<li><p><strong>GPU</strong>: No GPU acceleration available</p></li>
<li><p><strong>Integration</strong>: Requires NumPy arrays (no PyTorch tensors)</p></li>
<li><p><strong>Baseline</strong>: Reference for CPU performance comparison</p></li>
</ul>
</section>
<section id="api-performance-summary">
<h3>API Performance Summary<a class="headerlink" href="#api-performance-summary" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>API Pattern</p></th>
<th class="head"><p>Sample Rate Config</p></th>
<th class="head"><p>Ergonomics</p></th>
<th class="head"><p>Performance</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Custom <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></td>
<td><p>Manual (<code class="docutils literal notranslate"><span class="pre">fs=</span></code>)</p></td>
<td><p>Good</p></td>
<td><p>Fast</p></td>
<td><p>Complex custom logic</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
<td><p>Manual (<code class="docutils literal notranslate"><span class="pre">fs=</span></code>)</p></td>
<td><p>Very Good</p></td>
<td><p>Fast</p></td>
<td><p>Standard PyTorch integration</p></td>
</tr>
<tr class="row-even"><td><p><strong>Pipeline Operator</strong></p></td>
<td><p><strong>Automatic</strong></p></td>
<td><p><strong>Excellent</strong></p></td>
<td><p><strong>Fast</strong></p></td>
<td><p><strong>Recommended for TorchFX</strong></p></td>
</tr>
<tr class="row-odd"><td><p>SciPy <code class="docutils literal notranslate"><span class="pre">lfilter</span></code></p></td>
<td><p>Manual (<code class="docutils literal notranslate"><span class="pre">fs=</span></code>)</p></td>
<td><p>Fair</p></td>
<td><p>Fast (CPU only)</p></td>
<td><p>Baseline comparison</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Key Insight</strong>: The pipeline operator provides automatic sample rate configuration with negligible performance overhead, making it the most ergonomic choice without sacrificing speed.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../core-concepts/pipeline-operator.html"><span class="doc">Pipeline Operator - Functional Composition</span></a> - Detailed documentation on the pipeline operator pattern</p>
</div>
</section>
</section>
<section id="fir-filter-performance">
<h2>FIR Filter Performance<a class="headerlink" href="#fir-filter-performance" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">fir_bench.py</span></code> benchmark evaluates FIR filter performance across varying signal durations, channel counts, and execution backends (GPU, CPU, SciPy).</p>
<section id="fir-test-configuration">
<h3>FIR Test Configuration<a class="headerlink" href="#fir-test-configuration" title="Link to this heading">#</a></h3>
<p><strong>Filter Chain</strong>: 5 cascaded FIR filters with varying tap counts</p>
<ul class="simple">
<li><p>DesignableFIR: 101 taps, 1000 Hz cutoff</p></li>
<li><p>DesignableFIR: 102 taps, 5000 Hz cutoff</p></li>
<li><p>DesignableFIR: 103 taps, 1500 Hz cutoff</p></li>
<li><p>DesignableFIR: 104 taps, 1800 Hz cutoff</p></li>
<li><p>DesignableFIR: 105 taps, 1850 Hz cutoff</p></li>
</ul>
<p><strong>Test Parameters</strong>:</p>
<ul class="simple">
<li><p><strong>Durations</strong>: 5s, 60s, 180s, 300s, 600s (10 minutes)</p></li>
<li><p><strong>Channels</strong>: 1, 2, 4, 8, 12</p></li>
<li><p><strong>Backends</strong>: GPU (CUDA), CPU (PyTorch), SciPy (NumPy)</p></li>
<li><p><strong>Repetitions</strong>: 50 per configuration</p></li>
</ul>
<pre  class="mermaid">
        graph TB
    subgraph &quot;FIR Benchmark Test Matrix&quot;
        Input[&quot;Input Signal&lt;br/&gt;Variable duration &amp; channels&quot;]

        subgraph Filters[&quot;FIR Filter Chain&quot;]
            F1[&quot;FIR 101 taps&lt;br/&gt;1000 Hz&quot;]
            F2[&quot;FIR 102 taps&lt;br/&gt;5000 Hz&quot;]
            F3[&quot;FIR 103 taps&lt;br/&gt;1500 Hz&quot;]
            F4[&quot;FIR 104 taps&lt;br/&gt;1800 Hz&quot;]
            F5[&quot;FIR 105 taps&lt;br/&gt;1850 Hz&quot;]
        end

        subgraph Durations[&quot;Duration Sweep&quot;]
            D1[&quot;5 seconds&quot;]
            D2[&quot;60 seconds&quot;]
            D3[&quot;180 seconds&quot;]
            D4[&quot;300 seconds&quot;]
            D5[&quot;600 seconds&quot;]
        end

        subgraph Channels[&quot;Channel Sweep&quot;]
            C1[&quot;1 channel&quot;]
            C2[&quot;2 channels&quot;]
            C3[&quot;4 channels&quot;]
            C4[&quot;8 channels&quot;]
            C5[&quot;12 channels&quot;]
        end

        Input --&gt; F1
        F1 --&gt; F2
        F2 --&gt; F3
        F3 --&gt; F4
        F4 --&gt; F5

        Input --&gt; Durations
        Input --&gt; Channels
    end

    style Input fill:#e1f5ff
    style Filters fill:#fff5e1
    </pre><p><strong>FIR Benchmark Configuration</strong> - Tests performance across duration and channel count dimensions.</p>
</section>
<section id="fir-coefficient-pre-computation">
<h3>FIR Coefficient Pre-Computation<a class="headerlink" href="#fir-coefficient-pre-computation" title="Link to this heading">#</a></h3>
<p>FIR filters require coefficient computation before filtering. The benchmark explicitly pre-computes coefficients to exclude design time from performance measurements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">DesignableFIR</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>

<span class="c1"># Create filter chain</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">102</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">103</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">104</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1800</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1850</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Pre-compute coefficients before timing</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>

<span class="c1"># Now ready for benchmarking (coefficient design excluded)</span>
</pre></div>
</div>
<p><strong>Why Pre-Compute?</strong></p>
<ol class="arabic simple">
<li><p><strong>Separation of Concerns</strong>: Design time vs filtering time are separate</p></li>
<li><p><strong>Realistic Use Case</strong>: Coefficients are typically computed once and reused</p></li>
<li><p><strong>Fair Comparison</strong>: SciPy baseline also pre-computes coefficients</p></li>
</ol>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In production code, call <code class="xref py py-meth docutils literal notranslate"><span class="pre">compute_coefficients()</span></code> once during initialization, then reuse the filter for processing multiple audio files.</p>
</div>
</section>
<section id="fir-device-transfer-pattern">
<h3>FIR Device Transfer Pattern<a class="headerlink" href="#fir-device-transfer-pattern" title="Link to this heading">#</a></h3>
<p>The benchmark demonstrates proper device management for GPU acceleration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>

<span class="c1"># GPU benchmarking</span>
<span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">gpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>

<span class="c1"># CPU benchmarking (transfer back)</span>
<span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">cpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>

<span class="c1"># Calculate speedup</span>
<span class="n">speedup</span> <span class="o">=</span> <span class="n">cpu_time</span> <span class="o">/</span> <span class="n">gpu_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU speedup: </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Device Transfer Rules</strong>:</p>
<ol class="arabic simple">
<li><p>Move both <code class="docutils literal notranslate"><span class="pre">Wave</span></code> and filter chain to the same device</p></li>
<li><p>Pre-compute coefficients <strong>before</strong> moving to GPU</p></li>
<li><p>Time only the filtering operation (exclude transfers)</p></li>
<li><p>Move back to CPU for result saving</p></li>
</ol>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="gpu-acceleration.html"><span class="doc">GPU Acceleration</span></a> - Comprehensive guide to GPU device management</p>
</div>
</section>
<section id="fir-performance-characteristics">
<h3>FIR Performance Characteristics<a class="headerlink" href="#fir-performance-characteristics" title="Link to this heading">#</a></h3>
<p>FIR filters have distinct performance characteristics compared to IIR filters:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Characteristic</p></th>
<th class="head"><p>FIR Filters</p></th>
<th class="head"><p>Reason</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Computational Cost</strong></p></td>
<td><p>Higher</p></td>
<td><p>Convolution with many taps</p></td>
</tr>
<tr class="row-odd"><td><p><strong>GPU Advantage</strong></p></td>
<td><p>Excellent</p></td>
<td><p>High parallelism in convolution</p></td>
</tr>
<tr class="row-even"><td><p><strong>Memory Footprint</strong></p></td>
<td><p>Larger</p></td>
<td><p>Must store all tap coefficients</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Scaling with Taps</strong></p></td>
<td><p>Linear O(N)</p></td>
<td><p>More taps = more multiply-accumulate operations</p></td>
</tr>
<tr class="row-even"><td><p><strong>Scaling with Channels</strong></p></td>
<td><p>Excellent</p></td>
<td><p>Independent per-channel convolution</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>When FIR Filters Excel</strong>:</p>
<ul class="simple">
<li><p><strong>Long signals</strong> (&gt;60s): Amortizes setup overhead</p></li>
<li><p><strong>Many channels</strong> (≥4): Parallel convolution across channels</p></li>
<li><p><strong>GPU available</strong>: Convolution is highly parallel</p></li>
<li><p><strong>Linear phase required</strong>: Only FIR can provide linear phase</p></li>
</ul>
<p><strong>When to Avoid FIR</strong>:</p>
<ul class="simple">
<li><p><strong>Real-time processing</strong>: IIR filters have lower latency</p></li>
<li><p><strong>Limited memory</strong>: FIR coefficients consume more memory</p></li>
<li><p><strong>CPU-only, short signals</strong>: IIR may be faster</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For steep frequency responses, FIR filters require many taps (100+). Consider IIR filters if phase linearity is not critical.</p>
</div>
</section>
<section id="scipy-fir-baseline-implementation">
<h3>SciPy FIR Baseline Implementation<a class="headerlink" href="#scipy-fir-baseline-implementation" title="Link to this heading">#</a></h3>
<p>The benchmark includes a SciPy baseline for CPU performance comparison:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.signal</span><span class="w"> </span><span class="kn">import</span> <span class="n">firwin</span><span class="p">,</span> <span class="n">lfilter</span>

<span class="c1"># Design FIR coefficients using scipy</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">firwin</span><span class="p">(</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">firwin</span><span class="p">(</span><span class="mi">102</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">firwin</span><span class="p">(</span><span class="mi">103</span><span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b4</span> <span class="o">=</span> <span class="n">firwin</span><span class="p">(</span><span class="mi">104</span><span class="p">,</span> <span class="mi">1800</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b5</span> <span class="o">=</span> <span class="n">firwin</span><span class="p">(</span><span class="mi">105</span><span class="p">,</span> <span class="mi">1850</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>

<span class="c1"># Apply filters sequentially</span>
<span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># FIR filters have a = [1]</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b4</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b5</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>SciPy Characteristics</strong>:</p>
<ul class="simple">
<li><p><strong>CPU-only</strong>: No GPU acceleration</p></li>
<li><p><strong>Optimized</strong>: Uses NumPy’s optimized C/Fortran backend</p></li>
<li><p><strong>Reference</strong>: Establishes baseline CPU performance</p></li>
<li><p><strong>Compatibility</strong>: Requires NumPy arrays (not PyTorch tensors)</p></li>
</ul>
</section>
</section>
<section id="iir-filter-performance">
<h2>IIR Filter Performance<a class="headerlink" href="#iir-filter-performance" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">iir_bench.py</span></code> benchmark evaluates IIR (Infinite Impulse Response) filter performance using the same test matrix as FIR benchmarks but with recursive filters.</p>
<section id="iir-test-configuration">
<h3>IIR Test Configuration<a class="headerlink" href="#iir-test-configuration" title="Link to this heading">#</a></h3>
<p><strong>Filter Chain</strong>: 4 cascaded IIR filters</p>
<ul class="simple">
<li><p>HiButterworth: 1000 Hz cutoff, order 2</p></li>
<li><p>LoButterworth: 5000 Hz cutoff, order 2</p></li>
<li><p>HiChebyshev1: 1500 Hz cutoff, order 2</p></li>
<li><p>LoChebyshev1: 1800 Hz cutoff, order 2</p></li>
</ul>
<p><strong>Test Parameters</strong>:</p>
<ul class="simple">
<li><p><strong>Durations</strong>: 1s, 5s, 180s, 300s, 600s (10 minutes)</p></li>
<li><p><strong>Channels</strong>: 1, 2, 4, 8, 12</p></li>
<li><p><strong>Backends</strong>: GPU (CUDA), CPU (PyTorch), SciPy (NumPy)</p></li>
<li><p><strong>Repetitions</strong>: 50 per configuration</p></li>
</ul>
<pre  class="mermaid">
        graph TB
    subgraph &quot;IIR Benchmark Architecture&quot;
        Input[&quot;Input Signal&lt;br/&gt;Variable duration &amp; channels&quot;]

        subgraph Chain[&quot;IIR Filter Chain&quot;]
            F1[&quot;HiButterworth&lt;br/&gt;1000 Hz, order 2&quot;]
            F2[&quot;LoButterworth&lt;br/&gt;5000 Hz, order 2&quot;]
            F3[&quot;HiChebyshev1&lt;br/&gt;1500 Hz, order 2&quot;]
            F4[&quot;LoChebyshev1&lt;br/&gt;1800 Hz, order 2&quot;]
        end

        subgraph Setup[&quot;IIR-Specific Setup&quot;]
            Compute[&quot;compute_coefficients()&lt;br/&gt;Design b, a coefficients&quot;]
            MoveCoeff[&quot;move_coeff('cuda'/'cpu')&lt;br/&gt;Transfer to device&quot;]
        end

        subgraph Backends[&quot;Execution Backends&quot;]
            GPU[&quot;GPU: fchain(wave.ys)&quot;]
            CPU[&quot;CPU: fchain(wave.ys)&quot;]
            SciPy[&quot;SciPy: lfilter(b, a, signal)&quot;]
        end

        Input --&gt; F1
        F1 --&gt; F2
        F2 --&gt; F3
        F3 --&gt; F4

        F1 --&gt; Compute
        Compute --&gt; MoveCoeff
        MoveCoeff --&gt; GPU
        MoveCoeff --&gt; CPU

        F1 --&gt; SciPy
    end

    style Input fill:#e1f5ff
    style Chain fill:#fff5e1
    style Setup fill:#e8f5e1
    </pre><p><strong>IIR Benchmark Structure</strong> - Shows coefficient management and execution backends.</p>
</section>
<section id="iir-coefficient-management">
<h3>IIR Coefficient Management<a class="headerlink" href="#iir-coefficient-management" title="Link to this heading">#</a></h3>
<p>Unlike FIR filters, IIR filters have both numerator (<code class="docutils literal notranslate"><span class="pre">b</span></code>) and denominator (<code class="docutils literal notranslate"><span class="pre">a</span></code>) coefficients that must be explicitly managed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiButterworth</span><span class="p">,</span> <span class="n">LoButterworth</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>

<span class="c1"># Create IIR filter chain</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Move wave and module to GPU</span>
<span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># IIR-specific: compute and move coefficients</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>  <span class="c1"># Design b, a coefficients</span>
    <span class="n">f</span><span class="o">.</span><span class="n">move_coeff</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>       <span class="c1"># Move coefficients to GPU</span>

<span class="c1"># Now ready for GPU processing</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">fchain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Two-Step Device Transfer</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Module transfer</strong>: <code class="docutils literal notranslate"><span class="pre">fchain.to(&quot;cuda&quot;)</span></code> moves module parameters</p></li>
<li><p><strong>Coefficient transfer</strong>: <code class="docutils literal notranslate"><span class="pre">f.move_coeff(&quot;cuda&quot;)</span></code> moves filter coefficients</p></li>
</ol>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For IIR filters, you must <strong>both</strong> move the module to the device <strong>and</strong> call <code class="xref py py-meth docutils literal notranslate"><span class="pre">move_coeff()</span></code>. Forgetting the second step will cause runtime errors.</p>
</div>
</section>
<section id="iir-vs-fir-performance-trade-offs">
<h3>IIR vs FIR Performance Trade-offs<a class="headerlink" href="#iir-vs-fir-performance-trade-offs" title="Link to this heading">#</a></h3>
<p>IIR and FIR filters have fundamentally different performance characteristics:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Aspect</p></th>
<th class="head"><p>IIR Filters</p></th>
<th class="head"><p>FIR Filters</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Computational Cost</strong></p></td>
<td><p>Lower (fewer operations per sample)</p></td>
<td><p>Higher (convolution with many taps)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Memory Footprint</strong></p></td>
<td><p>Small (few coefficients: b, a)</p></td>
<td><p>Large (many tap coefficients)</p></td>
</tr>
<tr class="row-even"><td><p><strong>GPU Advantage</strong></p></td>
<td><p>Moderate (less parallelism)</p></td>
<td><p>High (highly parallel convolution)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Phase Response</strong></p></td>
<td><p>Non-linear</p></td>
<td><p>Can be linear (symmetric taps)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Stability</strong></p></td>
<td><p>Can be unstable if poorly designed</p></td>
<td><p>Always stable</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Filter Order</strong></p></td>
<td><p>Achieves sharp cutoff with low order</p></td>
<td><p>Requires many taps for sharp cutoff</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Performance Comparison Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># IIR: Order 8 Butterworth (16 coefficients total)</span>
<span class="n">iir_filter</span> <span class="o">=</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">44100</span><span class="p">)</span>
<span class="c1"># Coefficients: b (9 values) + a (9 values) = 18 total</span>

<span class="c1"># Equivalent FIR: ~150+ taps for similar frequency response</span>
<span class="n">fir_filter</span> <span class="o">=</span> <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">151</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">44100</span><span class="p">)</span>
<span class="c1"># Coefficients: 151 tap values</span>

<span class="c1"># IIR is ~8x more memory-efficient and faster on CPU</span>
<span class="c1"># FIR has better GPU parallelism and linear phase</span>
</pre></div>
</div>
<p><strong>Choosing Between IIR and FIR</strong>:</p>
<pre  class="mermaid">
        flowchart TD
    Start[&quot;Choose Filter Type&quot;]

    LinearPhase{&quot;Linear phase&lt;br/&gt;required?&quot;}
    Stability{&quot;Stability&lt;br/&gt;critical?&quot;}
    GPU{&quot;GPU&lt;br/&gt;available?&quot;}
    Memory{&quot;Memory&lt;br/&gt;constrained?&quot;}

    UseFIR[&quot;Use FIR Filters&lt;br/&gt;✓ Linear phase&lt;br/&gt;✓ Always stable&lt;br/&gt;✓ GPU-friendly&quot;]
    UseIIR[&quot;Use IIR Filters&lt;br/&gt;✓ Low memory&lt;br/&gt;✓ Low latency&lt;br/&gt;✓ Efficient CPU&quot;]

    Start --&gt; LinearPhase
    LinearPhase --&gt;|Yes| UseFIR
    LinearPhase --&gt;|No| Stability
    Stability --&gt;|Critical| UseFIR
    Stability --&gt;|Not critical| GPU
    GPU --&gt;|Yes, long signals| UseFIR
    GPU --&gt;|No or short signals| Memory
    Memory --&gt;|Yes| UseIIR
    Memory --&gt;|No| UseFIR

    style UseFIR fill:#e1ffe1
    style UseIIR fill:#e1f5ff
    </pre><p><strong>Filter Type Selection Decision Tree</strong> - Choose based on phase, stability, and resource constraints.</p>
</section>
<section id="iir-scipy-baseline">
<h3>IIR SciPy Baseline<a class="headerlink" href="#iir-scipy-baseline" title="Link to this heading">#</a></h3>
<p>The IIR benchmark includes SciPy baseline for comparison:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.signal</span><span class="w"> </span><span class="kn">import</span> <span class="n">butter</span><span class="p">,</span> <span class="n">cheby1</span><span class="p">,</span> <span class="n">lfilter</span>

<span class="c1"># Design IIR coefficients</span>
<span class="n">b1</span><span class="p">,</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b2</span><span class="p">,</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">cheby1</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>
<span class="n">b4</span><span class="p">,</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">cheby1</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1800</span><span class="p">,</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">)</span>

<span class="c1"># Apply filters sequentially</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">a3</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">b4</span><span class="p">,</span> <span class="n">a4</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>SciPy IIR Performance</strong>:</p>
<ul class="simple">
<li><p><strong>CPU-optimized</strong>: Highly optimized C implementation</p></li>
<li><p><strong>No GPU</strong>: SciPy doesn’t support CUDA</p></li>
<li><p><strong>Baseline</strong>: Reference for CPU performance</p></li>
<li><p><strong>Filter Design</strong>: Uses standard signal processing algorithms</p></li>
</ul>
</section>
</section>
<section id="performance-optimization-guidelines">
<h2>Performance Optimization Guidelines<a class="headerlink" href="#performance-optimization-guidelines" title="Link to this heading">#</a></h2>
<p>Based on the benchmarking results, follow these guidelines to optimize your TorchFX pipelines.</p>
<section id="when-to-use-gpu-acceleration">
<h3>When to Use GPU Acceleration<a class="headerlink" href="#when-to-use-gpu-acceleration" title="Link to this heading">#</a></h3>
<p>GPU acceleration provides the greatest benefit under specific conditions:</p>
<pre  class="mermaid">
        flowchart TD
    Start[&quot;Audio Processing Task&quot;]

    CheckDuration{&quot;Signal duration&lt;br/&gt;&gt; 60 seconds?&quot;}
    CheckChannels{&quot;Channels ≥ 4?&quot;}
    CheckBatch{&quot;Batch processing&lt;br/&gt;multiple files?&quot;}
    CheckFIR{&quot;Using FIR filters&lt;br/&gt;with &gt;100 taps?&quot;}
    CheckRealtime{&quot;Real-time&lt;br/&gt;low-latency requirement?&quot;}

    UseGPU[&quot;✓ Use GPU&lt;br/&gt;wave.to('cuda')&lt;br/&gt;fchain.to('cuda')&quot;]
    UseCPU[&quot;✓ Use CPU&lt;br/&gt;Default or wave.to('cpu')&quot;]

    Start --&gt; CheckDuration
    CheckDuration --&gt;|Yes| UseGPU
    CheckDuration --&gt;|No| CheckChannels
    CheckChannels --&gt;|Yes| UseGPU
    CheckChannels --&gt;|No| CheckBatch
    CheckBatch --&gt;|Yes| UseGPU
    CheckBatch --&gt;|No| CheckFIR
    CheckFIR --&gt;|Yes| UseGPU
    CheckFIR --&gt;|No| CheckRealtime
    CheckRealtime --&gt;|Yes| UseCPU
    CheckRealtime --&gt;|No| UseGPU

    style UseGPU fill:#e1ffe1
    style UseCPU fill:#e1f5ff
    </pre><p><strong>GPU Decision Tree</strong> - Follow this flowchart to determine optimal execution backend.</p>
<p><strong>GPU Performance Sweet Spot</strong>:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Factor</p></th>
<th class="head"><p>Threshold</p></th>
<th class="head"><p>Reasoning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Duration</strong></p></td>
<td><p>&gt; 60 seconds</p></td>
<td><p>Amortizes data transfer overhead</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Channels</strong></p></td>
<td><p>≥ 4 channels</p></td>
<td><p>Exploits parallel processing</p></td>
</tr>
<tr class="row-even"><td><p><strong>Batch Size</strong></p></td>
<td><p>&gt; 5 files</p></td>
<td><p>Transfer overhead amortized across batch</p></td>
</tr>
<tr class="row-odd"><td><p><strong>FIR Taps</strong></p></td>
<td><p>&gt; 100 taps</p></td>
<td><p>Convolution highly parallelizable</p></td>
</tr>
<tr class="row-even"><td><p><strong>IIR Chain</strong></p></td>
<td><p>≥ 3 filters</p></td>
<td><p>Accumulated compute benefits</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>CPU Preferred Cases</strong>:</p>
<ul class="simple">
<li><p><strong>Real-time processing</strong>: More predictable latency</p></li>
<li><p><strong>Short signals</strong> (&lt;30s): Transfer overhead dominates</p></li>
<li><p><strong>Single channel</strong>: Insufficient parallelism</p></li>
<li><p><strong>IIR filters only</strong>: Less GPU benefit than FIR</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>When in doubt, benchmark your specific workload. Use the patterns from the benchmark suite as templates.</p>
</div>
</section>
<section id="filter-chain-optimization">
<h3>Filter Chain Optimization<a class="headerlink" href="#filter-chain-optimization" title="Link to this heading">#</a></h3>
<p>Optimize filter chains by pre-computing coefficients and reusing filters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">DesignableFIR</span><span class="p">,</span> <span class="n">HiButterworth</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>

<span class="c1"># Create filter chain</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
    <span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Pre-compute coefficients once during initialization</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>

<span class="c1"># For IIR filters, also move coefficients to device</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s1">&#39;move_coeff&#39;</span><span class="p">):</span>
        <span class="n">f</span><span class="o">.</span><span class="n">move_coeff</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Process multiple files without re-computing coefficients</span>
<span class="n">audio_files</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;song1.wav&quot;</span><span class="p">,</span> <span class="s2">&quot;song2.wav&quot;</span><span class="p">,</span> <span class="s2">&quot;song3.wav&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">audio_file</span> <span class="ow">in</span> <span class="n">audio_files</span><span class="p">:</span>
    <span class="n">wave</span> <span class="o">=</span> <span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">audio_file</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span>  <span class="c1"># Uses cached coefficients</span>
    <span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;processed_</span><span class="si">{</span><span class="n">audio_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Optimization Benefits</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Coefficient caching</strong>: Compute once, reuse for all files</p></li>
<li><p><strong>Device pinning</strong>: Keep filters on GPU across iterations</p></li>
<li><p><strong>Batch amortization</strong>: Setup cost amortized over multiple files</p></li>
</ol>
</section>
<section id="device-placement-strategy">
<h3>Device Placement Strategy<a class="headerlink" href="#device-placement-strategy" title="Link to this heading">#</a></h3>
<p>Minimize device transfers by keeping processing on a single device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>

<span class="c1"># Strategy 1: Single device throughout (RECOMMENDED)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Load and move to device once</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;audio.wav&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Create filter chain on same device</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">12000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># All operations on same device</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span>

<span class="c1"># Move to CPU only for final I/O</span>
<span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output.wav&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Avoid Inefficient Transfers</strong> (Anti-pattern):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ❌ WRONG: Unnecessary device transfers</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;audio.wav&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">result1</span> <span class="o">=</span> <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">cpu_filter</span>  <span class="c1"># Transfer 1</span>
<span class="n">result2</span> <span class="o">=</span> <span class="n">result1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">gpu_filter</span>  <span class="c1"># Transfer 2</span>
<span class="n">result3</span> <span class="o">=</span> <span class="n">result2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">cpu_filter2</span>  <span class="c1"># Transfer 3</span>

<span class="c1"># ✅ CORRECT: Single device</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;audio.wav&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">cpu_filter</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gpu_filter</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">cpu_filter2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">cpu_filter</span> <span class="o">|</span> <span class="n">gpu_filter</span> <span class="o">|</span> <span class="n">cpu_filter2</span>
</pre></div>
</div>
<p><strong>Device Transfer Costs</strong>:</p>
<ul class="simple">
<li><p><strong>CPU → GPU</strong>: O(n) where n = number of samples</p></li>
<li><p><strong>GPU → CPU</strong>: O(n) where n = number of samples</p></li>
<li><p><strong>Impact</strong>: Can dominate for short signals</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="gpu-acceleration.html"><span class="doc">GPU Acceleration</span></a> - Comprehensive device management patterns</p>
</div>
</section>
<section id="memory-management-best-practices">
<h3>Memory Management Best Practices<a class="headerlink" href="#memory-management-best-practices" title="Link to this heading">#</a></h3>
<p>Optimize memory usage for large-scale processing:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Optimization</p></th>
<th class="head"><p>Implementation</p></th>
<th class="head"><p>Impact</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>In-place operations</strong></p></td>
<td><p>Use effects that modify tensors in-place where possible</p></td>
<td><p>Reduces memory allocations</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Chunked processing</strong></p></td>
<td><p>Process long audio in chunks</p></td>
<td><p>Prevents GPU OOM errors</p></td>
</tr>
<tr class="row-even"><td><p><strong>Coefficient caching</strong></p></td>
<td><p>Pre-compute and reuse filter coefficients</p></td>
<td><p>Eliminates redundant computation</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Device pinning</strong></p></td>
<td><p>Keep frequently-used filters on device</p></td>
<td><p>Reduces transfer overhead</p></td>
</tr>
<tr class="row-even"><td><p><strong>Batch size tuning</strong></p></td>
<td><p>Adjust batch size to fit GPU memory</p></td>
<td><p>Maximizes throughput</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Memory-Efficient Chunked Processing Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">process_long_audio_chunked</span><span class="p">(</span><span class="n">wave</span><span class="p">,</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">chunk_duration</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process very long audio in chunks to manage GPU memory.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    wave : Wave</span>
<span class="sd">        Input audio (can be on CPU or GPU)</span>
<span class="sd">    fchain : nn.Module</span>
<span class="sd">        Filter chain (must be on same device as intended chunks)</span>
<span class="sd">    chunk_duration : float</span>
<span class="sd">        Chunk duration in seconds</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Wave</span>
<span class="sd">        Processed audio</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">chunk_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">chunk_duration</span> <span class="o">*</span> <span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span>
    <span class="n">num_chunks</span> <span class="o">=</span> <span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">chunk_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">chunk_samples</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chunks</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">chunk_samples</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_samples</span><span class="p">,</span> <span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Extract chunk and move to GPU</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Process chunk on GPU</span>
        <span class="n">processed_chunk</span> <span class="o">=</span> <span class="n">chunk</span> <span class="o">|</span> <span class="n">fchain</span>

        <span class="c1"># Move back to CPU and store</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">processed_chunk</span><span class="o">.</span><span class="n">ys</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

        <span class="c1"># Clear GPU cache</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="c1"># Concatenate results</span>
    <span class="k">return</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;10_hour_recording.wav&quot;</span><span class="p">)</span>
<span class="n">fchain</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">process_long_audio_chunked</span><span class="p">(</span><span class="n">wave</span><span class="p">,</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">chunk_duration</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;processed.wav&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Chunked Processing Benefits</strong>:</p>
<ul class="simple">
<li><p>Processes arbitrarily long audio without OOM errors</p></li>
<li><p>Keeps GPU utilization high</p></li>
<li><p>Balances memory usage with throughput</p></li>
</ul>
</section>
</section>
<section id="benchmarking-your-own-pipelines">
<h2>Benchmarking Your Own Pipelines<a class="headerlink" href="#benchmarking-your-own-pipelines" title="Link to this heading">#</a></h2>
<p>Use these patterns to benchmark your custom TorchFX pipelines.</p>
<section id="basic-benchmarking-template">
<h3>Basic Benchmarking Template<a class="headerlink" href="#basic-benchmarking-template" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Configuration</span>
<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>
<span class="n">DURATION</span> <span class="o">=</span> <span class="mi">60</span>  <span class="c1"># seconds</span>
<span class="n">NUM_CHANNELS</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># repetitions for timing</span>

<span class="c1"># Generate test signal</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">NUM_CHANNELS</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLE_RATE</span> <span class="o">*</span> <span class="n">DURATION</span><span class="p">))</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">signal</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">)</span>

<span class="c1"># Create your processing pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">effect</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">peak</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Pre-compute coefficients</span>
<span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">pipeline</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;compute_coefficients&#39;</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>

<span class="c1"># Benchmark CPU</span>
<span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">cpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>

<span class="c1"># Benchmark GPU (if available)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Move IIR coefficients if needed</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">pipeline</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;move_coeff&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">move_coeff</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">gpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CPU time: </span><span class="si">{</span><span class="n">cpu_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU time: </span><span class="si">{</span><span class="n">gpu_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">cpu_time</span><span class="o">/</span><span class="n">gpu_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CPU time: </span><span class="si">{</span><span class="n">cpu_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU not available&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multi-configuration-benchmark">
<h3>Multi-Configuration Benchmark<a class="headerlink" href="#multi-configuration-benchmark" title="Link to this heading">#</a></h3>
<p>Test performance across multiple configurations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Test configurations</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>  <span class="c1"># seconds</span>
<span class="n">channel_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>

<span class="c1"># Create filter chain</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Pre-compute coefficients</span>
<span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">pipeline</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;compute_coefficients&#39;</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>

<span class="c1"># Benchmark grid</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">duration</span> <span class="ow">in</span> <span class="n">durations</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_counts</span><span class="p">:</span>
        <span class="c1"># Generate test signal</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLE_RATE</span> <span class="o">*</span> <span class="n">duration</span><span class="p">))</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">signal</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">)</span>

        <span class="c1"># CPU benchmark</span>
        <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">cpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>

        <span class="c1"># GPU benchmark</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="n">pipeline</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="n">gpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>
            <span class="n">speedup</span> <span class="o">=</span> <span class="n">cpu_time</span> <span class="o">/</span> <span class="n">gpu_time</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">gpu_time</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">speedup</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;duration&#39;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span>
            <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="n">channels</span><span class="p">,</span>
            <span class="s1">&#39;cpu_time&#39;</span><span class="p">:</span> <span class="n">cpu_time</span><span class="p">,</span>
            <span class="s1">&#39;gpu_time&#39;</span><span class="p">:</span> <span class="n">gpu_time</span><span class="p">,</span>
            <span class="s1">&#39;speedup&#39;</span><span class="p">:</span> <span class="n">speedup</span>
        <span class="p">})</span>

<span class="c1"># Convert to DataFrame for analysis</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># Save to CSV</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;benchmark_results.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="profiling-with-pytorch-profiler">
<h3>Profiling with PyTorch Profiler<a class="headerlink" href="#profiling-with-pytorch-profiler" title="Link to this heading">#</a></h3>
<p>For detailed performance analysis, use PyTorch’s built-in profiler:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>

<span class="c1"># Create pipeline</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">fx</span><span class="o">.</span><span class="n">Wave</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;audio.wav&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">fx</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Profile the pipeline</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
    <span class="n">activities</span><span class="o">=</span><span class="p">[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">profile_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">pipeline</span>

<span class="c1"># Print profiling results</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;cuda_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># Export for visualization</span>
<span class="n">prof</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="s2">&quot;trace.json&quot;</span><span class="p">)</span>
<span class="c1"># Open trace.json in chrome://tracing for detailed visualization</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference external" href="https://pytorch.org/docs/stable/profiler.html">PyTorch Profiler Documentation</a> - Official guide to PyTorch profiling tools</p>
</div>
</section>
</section>
<section id="complete-benchmarking-examples">
<h2>Complete Benchmarking Examples<a class="headerlink" href="#complete-benchmarking-examples" title="Link to this heading">#</a></h2>
<p>These complete examples demonstrate how to run comprehensive benchmarks for your specific use cases.</p>
<section id="example-1-api-pattern-comparison">
<h3>Example 1: API Pattern Comparison<a class="headerlink" href="#example-1-api-pattern-comparison" title="Link to this heading">#</a></h3>
<p>Compare different API patterns for your filter chain:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiChebyshev1</span><span class="p">,</span> <span class="n">LoButterworth</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>
<span class="n">DURATION</span> <span class="o">=</span> <span class="mi">120</span>  <span class="c1"># 2 minutes</span>
<span class="n">NUM_CHANNELS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Generate test signal</span>
<span class="n">signal_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">NUM_CHANNELS</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLE_RATE</span> <span class="o">*</span> <span class="n">DURATION</span><span class="p">))</span>
<span class="n">signal_data</span> <span class="o">=</span> <span class="n">signal_data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">signal_data</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal_data</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">wave</span> <span class="o">=</span> <span class="n">Wave</span><span class="p">(</span><span class="n">signal_data</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">)</span>

<span class="c1"># Pattern 1: Custom nn.Module class</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FilterChain</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f1</span> <span class="o">=</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f2</span> <span class="o">=</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_class</span><span class="p">():</span>
    <span class="n">fchain</span> <span class="o">=</span> <span class="n">FilterChain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fchain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">)</span>

<span class="c1"># Pattern 2: nn.Sequential</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_sequential</span><span class="p">():</span>
    <span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
        <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">wave</span><span class="o">.</span><span class="n">fs</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">fchain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">)</span>

<span class="c1"># Pattern 3: Pipe operator</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_pipe</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">HiChebyshev1</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="o">|</span> <span class="n">LoButterworth</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>

<span class="c1"># Benchmark each pattern</span>
<span class="n">class_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="n">test_class</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>
<span class="n">seq_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="n">test_sequential</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>
<span class="n">pipe_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="n">test_pipe</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Custom class: </span><span class="si">{</span><span class="n">class_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;nn.Sequential: </span><span class="si">{</span><span class="n">seq_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pipe operator: </span><span class="si">{</span><span class="n">pipe_time</span><span class="o">/</span><span class="n">REP</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-2-fir-filter-performance-analysis">
<h3>Example 2: FIR Filter Performance Analysis<a class="headerlink" href="#example-2-fir-filter-performance-analysis" title="Link to this heading">#</a></h3>
<p>Comprehensive FIR filter benchmarking across durations and channel counts:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">DesignableFIR</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Test matrix</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">600</span><span class="p">]</span>
<span class="n">channel_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">duration</span> <span class="ow">in</span> <span class="n">durations</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_counts</span><span class="p">:</span>
        <span class="c1"># Generate test signal</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLE_RATE</span> <span class="o">*</span> <span class="n">duration</span><span class="p">))</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">signal</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">wave</span> <span class="o">=</span> <span class="n">Wave</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">)</span>

        <span class="c1"># Create FIR filter chain</span>
        <span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
            <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">102</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
            <span class="n">DesignableFIR</span><span class="p">(</span><span class="n">num_taps</span><span class="o">=</span><span class="mi">103</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Pre-compute coefficients</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>

        <span class="c1"># GPU benchmark</span>
        <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">gpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>

        <span class="c1"># CPU benchmark</span>
        <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">cpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">wave</span> <span class="o">|</span> <span class="n">fchain</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">REP</span><span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;duration_sec&#39;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span>
            <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="n">channels</span><span class="p">,</span>
            <span class="s1">&#39;gpu_time_sec&#39;</span><span class="p">:</span> <span class="n">gpu_time</span><span class="p">,</span>
            <span class="s1">&#39;cpu_time_sec&#39;</span><span class="p">:</span> <span class="n">cpu_time</span><span class="p">,</span>
            <span class="s1">&#39;speedup&#39;</span><span class="p">:</span> <span class="n">cpu_time</span> <span class="o">/</span> <span class="n">gpu_time</span>
        <span class="p">})</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Duration: </span><span class="si">{</span><span class="n">duration</span><span class="si">}</span><span class="s2">s, Channels: </span><span class="si">{</span><span class="n">channels</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;GPU: </span><span class="si">{</span><span class="n">gpu_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s, CPU: </span><span class="si">{</span><span class="n">cpu_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">cpu_time</span><span class="o">/</span><span class="n">gpu_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>

<span class="c1"># Save results</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;fir_benchmark.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results saved to fir_benchmark.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-3-iir-filter-performance-analysis">
<h3>Example 3: IIR Filter Performance Analysis<a class="headerlink" href="#example-3-iir-filter-performance-analysis" title="Link to this heading">#</a></h3>
<p>Complete IIR filter benchmarking with coefficient management:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timeit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx</span><span class="w"> </span><span class="kn">import</span> <span class="n">Wave</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchfx.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HiButterworth</span><span class="p">,</span> <span class="n">LoButterworth</span><span class="p">,</span> <span class="n">HiChebyshev1</span><span class="p">,</span> <span class="n">LoChebyshev1</span>

<span class="n">SAMPLE_RATE</span> <span class="o">=</span> <span class="mi">44100</span>
<span class="n">REP</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Test matrix</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">600</span><span class="p">]</span>
<span class="n">channel_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">duration</span> <span class="ow">in</span> <span class="n">durations</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_counts</span><span class="p">:</span>
        <span class="c1"># Generate test signal</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLE_RATE</span> <span class="o">*</span> <span class="n">duration</span><span class="p">))</span>
        <span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">signal</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">signal</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">wave</span> <span class="o">=</span> <span class="n">Wave</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">)</span>

        <span class="c1"># Create IIR filter chain</span>
        <span class="n">fchain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">HiButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
            <span class="n">LoButterworth</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
            <span class="n">HiChebyshev1</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
            <span class="n">LoChebyshev1</span><span class="p">(</span><span class="n">cutoff</span><span class="o">=</span><span class="mi">1800</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">SAMPLE_RATE</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># GPU benchmark</span>
        <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="c1"># Compute and move coefficients</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">()</span>
            <span class="n">f</span><span class="o">.</span><span class="n">move_coeff</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="n">gpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="n">fchain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">),</span>
            <span class="n">number</span><span class="o">=</span><span class="n">REP</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>

        <span class="c1"># CPU benchmark</span>
        <span class="n">wave</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">fchain</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fchain</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">move_coeff</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="n">cpu_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="n">fchain</span><span class="p">(</span><span class="n">wave</span><span class="o">.</span><span class="n">ys</span><span class="p">),</span>
            <span class="n">number</span><span class="o">=</span><span class="n">REP</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">REP</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;duration_sec&#39;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span>
            <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="n">channels</span><span class="p">,</span>
            <span class="s1">&#39;gpu_time_sec&#39;</span><span class="p">:</span> <span class="n">gpu_time</span><span class="p">,</span>
            <span class="s1">&#39;cpu_time_sec&#39;</span><span class="p">:</span> <span class="n">cpu_time</span><span class="p">,</span>
            <span class="s1">&#39;speedup&#39;</span><span class="p">:</span> <span class="n">cpu_time</span> <span class="o">/</span> <span class="n">gpu_time</span>
        <span class="p">})</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Duration: </span><span class="si">{</span><span class="n">duration</span><span class="si">}</span><span class="s2">s, Channels: </span><span class="si">{</span><span class="n">channels</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;GPU: </span><span class="si">{</span><span class="n">gpu_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s, CPU: </span><span class="si">{</span><span class="n">cpu_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">cpu_time</span><span class="o">/</span><span class="n">gpu_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>

<span class="c1"># Save results</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;iir_benchmark.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results saved to iir_benchmark.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>Key takeaways for optimizing TorchFX performance:</p>
<ol class="arabic simple">
<li><p><strong>GPU Acceleration</strong>: Use GPU for long signals (&gt;60s), multi-channel audio (≥4 channels), and batch processing</p></li>
<li><p><strong>Filter Choice</strong>: FIR filters excel on GPU with parallel convolution; IIR filters are more CPU-efficient</p></li>
<li><p><strong>API Pattern</strong>: Pipeline operator provides best ergonomics with automatic sample rate configuration and minimal overhead</p></li>
<li><p><strong>Coefficient Caching</strong>: Pre-compute filter coefficients once and reuse for multiple files</p></li>
<li><p><strong>Device Management</strong>: Minimize transfers by keeping all processing on one device</p></li>
<li><p><strong>Memory</strong>: Use chunked processing for very long audio files to prevent OOM errors</p></li>
<li><p><strong>Benchmarking</strong>: Use the provided templates to measure performance of your specific pipelines</p></li>
</ol>
<p>GPU acceleration can provide 5-20x speedups for appropriate workloads. Follow the decision trees and best practices in this guide to maximize throughput in your audio processing pipelines.</p>
</section>
<section id="related-guides">
<h2>Related Guides<a class="headerlink" href="#related-guides" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="gpu-acceleration.html"><span class="doc">GPU Acceleration</span></a> - Comprehensive GPU device management guide</p></li>
<li><p><span class="xref std std-doc">../filters/iir-filters</span> - IIR filter design and usage</p></li>
<li><p><span class="xref std std-doc">../filters/fir-filters</span> - FIR filter design and usage</p></li>
<li><p><a class="reference internal" href="pytorch-integration.html"><span class="doc">PyTorch Integration</span></a> - Integration with PyTorch ecosystem</p></li>
<li><p><a class="reference internal" href="multi-channel.html"><span class="doc">Multi-Channel Processing</span></a> - Multi-channel processing patterns</p></li>
</ul>
</section>
<section id="external-resources">
<h2>External Resources<a class="headerlink" href="#external-resources" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/profiler.html">PyTorch Profiler</a> - Profiling PyTorch code</p></li>
<li><p><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/">CUDA Best Practices Guide</a> - NVIDIA optimization guide</p></li>
<li><p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/signal.html">SciPy Signal Processing</a> - SciPy signal processing reference</p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html">PyTorch Performance Tuning</a> - PyTorch optimization guide</p></li>
</ul>
</section>
</section>

<div class="section ablog__blog_comments">
   
</div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="multi-channel.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Multi-Channel Processing</p>
      </div>
    </a>
    <a class="right-next"
       href="../api_stability.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">API Stability and Backward Compatibility</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-methodology">Benchmark Methodology</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-suite-architecture">Benchmark Suite Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-signal-generation">Test Signal Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#timing-methodology">Timing Methodology</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#api-performance-comparison">API Performance Comparison</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-configuration">Test Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-pattern-1-custom-nn-module-class">API Pattern 1: Custom nn.Module Class</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-pattern-2-nn-sequential">API Pattern 2: nn.Sequential</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-pattern-3-pipeline-operator-pipe">API Pattern 3: Pipeline Operator (Pipe)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-pattern-4-scipy-baseline">API Pattern 4: SciPy Baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-performance-summary">API Performance Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fir-filter-performance">FIR Filter Performance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fir-test-configuration">FIR Test Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fir-coefficient-pre-computation">FIR Coefficient Pre-Computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fir-device-transfer-pattern">FIR Device Transfer Pattern</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fir-performance-characteristics">FIR Performance Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scipy-fir-baseline-implementation">SciPy FIR Baseline Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iir-filter-performance">IIR Filter Performance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iir-test-configuration">IIR Test Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iir-coefficient-management">IIR Coefficient Management</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iir-vs-fir-performance-trade-offs">IIR vs FIR Performance Trade-offs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iir-scipy-baseline">IIR SciPy Baseline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-optimization-guidelines">Performance Optimization Guidelines</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-gpu-acceleration">When to Use GPU Acceleration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filter-chain-optimization">Filter Chain Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-placement-strategy">Device Placement Strategy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-management-best-practices">Memory Management Best Practices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmarking-your-own-pipelines">Benchmarking Your Own Pipelines</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-benchmarking-template">Basic Benchmarking Template</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-configuration-benchmark">Multi-Configuration Benchmark</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#profiling-with-pytorch-profiler">Profiling with PyTorch Profiler</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-benchmarking-examples">Complete Benchmarking Examples</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-api-pattern-comparison">Example 1: API Pattern Comparison</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-fir-filter-performance-analysis">Example 2: FIR Filter Performance Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-3-iir-filter-performance-analysis">Example 3: IIR Filter Performance Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#related-guides">Related Guides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#external-resources">External Resources</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/matteospanio/torchfx/edit/main/docs/source/guides/advanced/performance.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/guides/advanced/performance.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2026, Matteo Spanio.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>